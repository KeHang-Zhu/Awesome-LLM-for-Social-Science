# Awesome-LLM-for-Social-Science 

\
[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)



This repo aims to track research works in the emergent displine of using LLM agent as human subject in social science

We strongly encourage the researchers that want to promote their fantastic work to the LLM social science to make pull request to update their paper's information!

:satisfied: Please check out the recent paper for LLM-powered Social Science: [Automated Social Science: Language Models as Scientist and Subjects](https://arxiv.org/abs/2404.11794)

To catch up with the latest research progress, this repository will be actively maintained as well as our released survey paper.

--- 

## Contents

- [Papers](#papers)
  - [LLMs as subjects](#experiment)
  - [Objections to LLMs as subjects](#experiment)



--- 

# Papers 

<b>1. LLMs as subjects</b>

| **Paper**| **Author(s)**  | **LLM (Agent)** | **Category** | **Relicated experiments** |**Publication** | **Link** |
|:---:|:----|:---:|:---:|:---:|:---:|:---:|
Automated Social Science: Language Models as Scientist and Subjects |BS Manning et.al.| GPT-4 | Economic and Sociology | Auction, Bargain, Job interview| Arxiv 2024| [[Link]](https://arxiv.org/abs/2404.11794) |
| Large language models as simulated economic agents: What can we learn from homo silicus? |JJ Horton| GPT-3 | Economic and Psychology| Status Quo Bias| Arxiv 2023| [[Link]](https://www.nber.org/papers/w31122) |
| Generative Agents: Interactive Simulacra of Human Behavior | JS Park et.al. | gpt3.5-turbo | Sociology | \ |UIST 23|[[Link]](https://arxiv.org/pdf/2304.03442.pdf) |
| Measuring Implicit Bias in Explicitly Unbiased Large Language Models |X Bai et.al.| GPT3.5/GPT-4/ opensource| Psychology | Implicit bias |ArXiv 23|[[Link]](https://arxiv.org/pdf/2402.04105.pdf) |
| Out of One, Many: Using Language Models to Simulate Human Samples|LP Argyle et.al.| GPT3.5 | Politics | \ |Political Analysis 23|[[Link]](https://www.cambridge.org/core/journals/political-analysis/article/abs/out-of-one-many-using-language-models-to-simulate-human-samples/035D7C8A55B237942FB6DBAD7CAA4E49) |
| Using GPT for Market Research| J Brand et.al. | GPT3.5 | Marketing | demand curves |Harvard Business School Working Paper 23|[[Link]](https://www.hbs.edu/ris/Publication%20Files/23-062_b8fbedcd-ade4-49d6-8bb7-d216650ff3bd.pdf) |
|Using large language models to simulate multiple humans and replicate human subject studies|G Aher et.al.| GPT3.5 |  Sociology | \ |PMLR 23|[[Link]](https://arxiv.org/abs/2208.10264) |
|Frontiers: Determining the Validity of Large Language Models for Automated Perceptual Analysis|P Li et.al.| GPT3.5 |  Marketing | Car brands preference |Market Science 24|[[Link]](https://pubsonline.informs.org/doi/10.1287/mksc.2023.0454) |
|CogBench: a large language model walks into a psychology lab|J Coda-Forno et.al.| Fine-tune GPT |  Psychology | 7 classical Psychological experiments |ArXiv 24|[[Link]](https://arxiv.org/abs/2402.18225) |
|LM-driven Imitation of Subrational Behavior : Illusion or Reality?|A Coletta et.al.| GPT4 | Psychology | \ |ArXiv 24|[[Link]](https://arxiv.org/pdf/2402.18225.pdf) |


<b>2. Objections to LLMs as subjects</b>

| **Paper** | **Author(s)**  | **LLM (Agent)** | **Category** | **Relicated experiments** |**Publication** | **Link** |
|:---:|:----|:---:|:---:|:---:|:---:|:---:|
|Large language models cannot replace human participants because they cannot portray identity groups|A Wang et.al.| 4 LLMs | Sociology | Minority groups| Arxiv 2024| [[Link]](https://arxiv.org/pdf/2402.01908.pdf) |




<b>2. To be categorized</b>

Recent work studies the possibility of using LLMs to simulate and analyze human behaviors (Ziems et al., 2023; Chiang & Lee, 2023; Aher et al., 2023; Sejnowski, 2023; Horton, 2023; Argyle et al., 2023; Korinek, 2023; Williams et al., 2023).












